ACADA Learning:  Kubernetes   || k8s 

Kubernetes is an ochestration engine and open-source platform
we use it to manage containarized applciations

1. Container ochestration
2. Container management 

Benefits:
  container deployement
  automated scaling 
  container management and ochestration
  load balancing
  Open source
  horizontal scaling
  optimizing cost 
  self healing 
  cloud migration

  kubernetes was released on july 21, 2015

  1-5 years 

  kubernetes achitecure:
    Service Discovery

Control plane/master:
  API server
  etcd
  scheduler
  Controller manager

Worker Nodes:
  kubelet
  kube-proxy

Command Line utility:
  for Docker    [ docker ] docker build
  for maven      [ mvn ]      mvn package
  for k8s       [ kubectl ]   kubectl apply 


  Kubernetes components 

  Cluster  -----> Worker Nodes  --->  pods  ----> Containers  ---> images ---> Appplication and Base image

Kubernetes Objects:
  Controller Manager:
    ReplicationController
    Deployment
    ReplicaSet
    DaemonSet
    StatefulSets
    Job

  Service:
    ClusterIP
    Service
    NodePort
    LoadBalancer
    ExternalName


  https://labs.play-with-k8s.com/

  Installtion of K8S:
    1. Self managed   --- Manage the control plane
    2. Managed / Cloud Managed  ---  Cloud provider is managing the control plane
 
    1. Self managed:
      minikube    --- single node cluster
      kubeadm     --- we can setup multiple nodes withing a cluster

    2. Managed/Cloud Managed:
      EKS        ---  Elastic Kubernetes Service (AWS)
      AKS        ---  Azure Kubernetes Service  (Azure)
      GKE        ---  Google Kubernetes Engine   (GCP)

      KOPS

  How do we deploy in docker:
    Imperative       -----  command
    docker run / create 
    docker service create


    Declarative --- Files + command
    docker-compose up
    docker-compose down
    docker stack deploy --docker-compose-file web.yml

  How do deploy in K8s:
    Imperative  --Command
    kubectl create namespace test
    kubectl create ns prod

    Declarative --File (Manifest files) + commands
    track file/record


Open all Port:

Kubernetes Installtion:
#!/bin/bash
# t2 Medium
# Common stages for both master and worker nodes
# This can be use as user data in launch template or launch configutions
sudo hostname master
sudo -i
sudo swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

sudo apt update -y
sudo apt install -y apt-transport-https -y

sudo curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

sudo cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
sudo apt update -y
sudo apt install -y kubelet kubeadm  containerd kubectl
# apt-mark hold will prevent the package from being automatically upgraded or removed.

sudo apt-mark hold kubelet kubeadm kubectl containerd

sudo cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

sudo cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF

sudo sysctl --system

sudo mkdir -p /etc/containerd
sudo containerd config default | sudo tee /etc/containerd/config.toml
sudo systemctl restart containerd

# Enable and start kubelet service
sudo systemctl daemon-reload
sudo systemctl start kubelet
sudo systemctl enable kubelet.service

#step2
kubeadm init

#step3
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config      

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

#Step4
sudo kubeadm join 172.31.24.209:6443 --token 8bdmlp.0v7ee3j8rj8gcuvs \
        --discovery-token-ca-cert-hash sha256:edb07e2a5094746fb48fb9e270878423ffb7cde60ca05c654710b5839d6d8dc6


kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml



creating namespace using Declarative file (Manifest file)

.yaml .yml

namespaces:
  Is a virtual cluster within your cluster
  Is it use to isolate your environment/ projects/teams
  used for securing k8s

namespaces = ns

how we deploy in k8s:
*Imperative 
kubectl get ns

kubectl create ns test
kubectl get ns

*Declarative
we deploy using Manifest files .yml

apiVersion: v1
kind: Namespace
metadata:
  name: prod

kubectl apply -f ns.yml --dry-run=client


apiVersion: v1
kind: Pod
metadata:
  name: webapp
  namespace: dev
  label: 
    app: webapp
spec:
  containers:
  - name: webapp
    image: acadalearning/java-web-app
    ports:
    - containerPort: 8080


kubectl config set-context --current --namespace=dev
kubectl get pod


kubectl api-resources | grep Pod

.yml

apiVersion: v1
kind: Pod
metadata:
  name: webapp
  namespace: dev
  labels:
    app: webapp
spec:
  containers:
  - name: webapp-c
    image: acadalearning/java-web-app
    ports:
    - containerPort: 8080




apiVersion: v1
kind: Pod
metadata:
  name: hello-pod
  namespace: dev
  labels:
    app: hello
spec:
  containers:
  - name: hello-c
    image: joveluro/helloworld
    ports:
    - containerPort: 80

--------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: webapp
  namespace: dev
  labels:
    app: webapp
spec:
  containers:
  - name: webapp-c
    image: acadalearning/java-web-app
    ports:
    - containerPort: 8080



apiVersion: v1
kind: Service
metadata:
  name: webapp-svc 
  namespace: dev
spec:
  type: ClusterIP
  selector:
    app: webapp
  ports:
  - port: 80
    targetPort: 8080



NodePort and LoadBalancer Service have a port range:
  30000 -- 32767

apiVersion: v1
kind: Service
metadata:
  name: webapp-svc
  namespace: dev
spec:
  type: NodePort
  selector:
    app: webapp
  ports:
  - targetPort: 8080
    port: 80
    nodePort: 31000



app exposed port: 8080
svc exposed port: 80
NodePort exposed port: 31000



Kubernetes note responding to localhost:
run these command on all the nodes
sudo vi /etc/cloud/cloud.cfg
change the preserve hostname from false to true

sudo vi /etc/hostname
change the hostname the the desdired or specifid hostname
reboot the all the instance

kubectl getn nodes

on master run this:
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml


FQDN = <podname>.<NS>.<cluster.local>
       curl -v webapp.prod.webappsvc.cluster.local

Service descovery: is what applciations uses to talk to each other in the same namespace (they use service name)

Fully qualified Domain name: applications uses FQDN to talk to each other in the same namespace and accross namespaces
                             is uses the full name to establish commmunication externaly (DNS)

CONTROLLER MANAGERS:

ReplicationController:
====================

apiVersion: v1
kind: Pod
metadata:
  name: webapp
  namespace: dev
  labels:
    app: webapp
----------------------------
spec:
  containers:
  - name: webapp-c
    image: acadalearning/java-web-app
    ports:
    - containerPort: 8080

=======================================================
----------------------------------- Controllers
apiVersion: v1  
kind: ReplicationController
metadata:
  name: webapp-RC
  namespace: dev
spec:
  selector:
    app: webapp
----------------------------------- Pods
  template: 
    metadata:
      name: webapp-pod 
      labels:
        app: webapp
----------------------------------- Containers
    spec: 
      containers:
      - name: webapp-c
        image: acadalearning/java-web-app
        ports:
        - containerPort: 8080


apiVersion: v1
kind: ReplicationController
metadata:
  name: webapp-RC
  namespace: dev
spec:
  selector:
    app: webapp
  template: 
    metadata:
      name: webapp-pod 
      labels:
        app: webapp
    spec: 
      containers:
      - name: webapp-c
        image: acadalearning/java-web-app
        ports:
        - containerPort: 8080

kubectl scale rc webapp-rc --replicas=8



ReplicaSet:

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myapp-rs
spec:
  replicas: 6
  selector:
    matchLabels:
      tier: myapp
  template:
    metadata:
      name: myapp-pod
      labels:
        tier: myapp
    spec:
      containers:
      - name: myapp-c
        image: acadalearning/myapp
        ports:
        - containerPort: 8080
---

apiVersion: v1
kind: Service
metadata:
  name: myapp-svc
spec:
  selector:
    tier: myapp
  ports:
  - targetPort: 8080
    port: 80
    nodePort: 30200
  type: NodePort



DaemonSet:

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: grafana
spec:
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      name: grafana
      labels:
        app: grafana
  template:
    metadata:
      name: prometheus
      labels:
        app: prometheus
    spec:
      containers:
      - name: grafana
        image: grafana/grafana
        ports: 
        - containerPort: 3000

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
spec:
  type: NodePort
  selector:
    app: grafana
  ports:
  - targetPort: 3000
    port: 80

------------------------------------------


WORKLOAD and SCHEDULE
- Labels:
  A label is a key value pair that is attached to a kubernetes resource, eg POD
  labels can be aatached to resources at creation time, as well as added and modified at anytime.

- Selectors:
  A label selector can be used to organise kubernetes resources that have labels
  An equality based selector defines a condition for selecting resources that have specific label value.
  A set-based selector defines a condition for selecting resources that have a label values withing the specified set of values.
  

  labels:
    acada: grafana
    tair: webapp
    acada: myapp


  selector:
    app: prometheus


Deployment:


apiVersion: apps/v1
kind: Deployment
metadata:
  name: springapp
  namespace: dev
spec:
  selector:
    matchLabels:
      app: springapp
  replicas: 3
  template:
    metadata:
      name: springapp
      labels:
        app: springapp
    spec:
      containers:
      - name: springapp
        image: acadalearning/spring-boot-mongo
        ports:
        - containerPort: 8080
        env:
        - name: MONGO_DB_USERNAME:
          value: devdb
        - name: MONGO_DB_PASSWORD:
          value: devdb@123
        - name: MONGO_DB_HOSTNAME:
          value: mongo
      
---
apiVersion: v1
kind: Service
metadata:
  name: springapp
spec:
  selector:
    app: springapp
  ports:
  - port: 80
    targetPort: 8080
  type: NodePort





apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: mongodb
  namespace: dev
spec:
  selector:
    matchLabels:
      app: mongodb
  template:
    metadata:
      name: mongodb
      labels:
        app: mongodb
    spec:
      volumes:
      - name: hostpathvol
        hostPath:
          path: /tmp/mongodbbkp
      containers:
      - name: mongodb
        image: mongo
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: devdb
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: devdb@123
        volumeMounts:
        - name: hostpathvol
          mountPath: /data/db

---
apiVersion: v1
kind: Service
metadata:
  name: mongo
spec:
  type: ClusterIP
  selector:
    app: mongodb
  ports:
  - port: 27017
    targetPort: 27017



Recreate:

  Note:
    version 1 = 4 replicas
    version 2 = 4 replicas 


apiVersion: apps/v1
kind: Deployment
metadata:
  name: springapp
  namespace: dev
spec:
  selector:
    matchLabels:
      app: springapp
  strategy: 
    type: Recreate
  replicas: 3
  template:
    metadata:
      name: springapp
      labels:
        app: springapp
    spec:
      containers:
      - name: springapp
        image: acadalearning/spring-boot-mongo
        ports:
        - containerPort: 8080


RollingUpdate:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: springapp
  namespace: dev
spec:
  selector:
    matchLabels:
      app: springapp
  strategy: 
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  minReadySeconds: 30
  replicas: 4
  template:
    metadata:
      name: springapp
      labels:
        app: springapp
    spec:
      containers:
      - name: springapp
        image: acadalearning/uba
        ports:
        - containerPort: 8080


version 1 = 4 replicas
version 2 = 4 replicas

=====================================
Deployment strategies:
Blue / Green: version 4 with 4 replicas  //    version 5 with 4 replicas
            


RollingUpdate : it replaces the pod running the old version of the application with 
                the new version of pod, one by one without downtime

Canary: 
  Client Base:
    Asia = 5%
    Africa = 100%
    America = 0%
    Europe = 15%
  Age based:
    youth 
    Adult
    Children

Recreate: terminates all exsisting pod before creating the new ones

Ramped slow rollout: it rolls out the replicas of the new version while in parallel, 
                    shutting the old replicas 

Best-effort contrlled rollout

==========================================================


VOLUMES:

NFS:
*provision a new instance
sudo hostname nfs
sudo apt-get update
sudo apt install nfs-kernal-server -y 


Create the export directory:

sudo mkdir -p /mnt/share

sudo vi /etc/exports


/srv/nfs4        gss/krb5i(rw,sync,fsid=0,crossmnt,no_subtree_check)

/mnt/share *(rw,sync,no_subtree_check,no_root_squash)


sudo apt-get update 
sudo apt-get install nfs-common -y


apiVersion: apps/v1
kind: Deployment
metadata:
  name: springapp
  namespace: dev
spec:
  selector:
    matchLabels:
      app: springapp
  replicas: 3
  template:
    metadata:
      name: springapp
      labels:
        app: springapp
    spec:
      containers:
      - name: springapp
        image: acadalearning/spring-boot-mongo
        ports:
        - containerPort: 8080
        env:
        - name: MONGO_DB_USERNAME
          value: devdb
        - name: MONGO_DB_PASSWORD
          value: devdb@123
        - name: MONGO_DB_HOSTNAME
          value: mongo
#
---
apiVersion: v1
kind: Service
metadata:
  name: springapp
spec:
  selector:
    app: springapp
  ports:
  - port: 80
    targetPort: 8080
  type: NodePort

---
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: mongodbrs
spec:
  selector:
    matchLabels:
      app: mongodb
  template:
    metadata:
      name: mongodbpod
      labels:
        app: mongodb
    spec:
      volumes:
      - name: nfsvol
        nfs:
          server: 172.31.26.89
          path: /mnt/share
      containers:
      - name: mongodb-c
        image: mongo
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: devdb
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: devdb@123
        volumeMounts:
        - name: nfsvol
          mountPath: /data/db

---
apiVersion: v1
kind: Service
metadata:
  name: mongo
spec:
  type: ClusterIP
  selector:
    app: mongodb
  ports:
  - port: 27017
    targetPort: 27017


Persistent Volume: PV
Storage class
5000GB

apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
  namespace: dev
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: manual
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /mnt/share
    server: 172.31.26.89



Persistent volume Claim: PVC

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec: 
  storageClassName: manual
  resources:
    requests:
      storage: 2Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce

------------------------------
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: mongodbrs
spec:
  selector:
    matchLabels:
      app: mongodb
  template:
    metadata:
      name: mongodbpod
      labels:
        app: mongodb
    spec:
      containers:
      - name: mongodb-c
        image: mongo
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: devdb
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: devdb@123
        volumeMounts:
        - name: nfsvol
          mountPath: /data/db
      volumes:
      - name: nfsvol
        persistentVolumeClaim:
          claimName: nfs-pvc

HaProxy:





frontend haproxynode
    bind *:80
    mode http
    default_backend backendServers
    
backend backendServers
    balance roundrobin
    option forwardfor
    http-request set-header X-Forwarded-Port %[dst_port]
    http-request add-header X-Forwarded-Proto https if { ssl_fc }
    option httpchk HEAD / HTTP/1.1\r\nHost:localhost
    server ip-172-31-84-73 172.31.84.73:32459 check
    server ip-172-31-30-196 172.31.30.196:32459 check
    #server node2 <IP>:<PORT> check

nginx:



54.164.75.73:32459

------------------------------------
ConfigMap and Secret:

*A ConfigMap is an API object used to store non-confidential data in key-value pairs
*Pods can consume configMap as environmental variables, command-line arguments or as 
 configuration files in a volume.

ConfigMap are passed or password as plain text or clear text 


Secrets:
  secrets are API objects used to store confidential data in key-value pairs


devdb@123   = ZGV2ZGJAMTIz


ConfigMap:

apiVersion: v1
kind: ConfigMap
metadata:
  name: mongo-config
data:
  db-username: devdb


secrets:

kind: Secret
apiVersion: v1
metadata:
  name: mongo-passwd
type: Opaque
stringData: 
  db-password: ZGV2ZGJAMTIz



------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: springapp
  namespace: dev
spec:
  selector:
    matchLabels:
      app: springapp
  replicas: 3
  template:
    metadata:
      name: springapp
      labels:
        app: springapp
    spec:
      containers:
      - name: springapp
        image: acadalearning/spring-boot-mongo
        ports:
        - containerPort: 8080
        env:
        - name: MONGO_DB_USERNAME
          value: db-username
        - name: MONGO_DB_PASSWORD
          value: db-password
        - name: MONGO_DB_HOSTNAME
          value: mongo
#
---
apiVersion: v1
kind: Service
metadata:
  name: springapp
spec:
  selector:
    app: springapp
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mongo-config
data:
  db-username: devdb

---
#secrets:

kind: Secret
apiVersion: v1
metadata:
  name: mongo-passwd
type: Opaque
stringData: 
  db-password: ZGV2ZGJAMTIz






apiVersion: v1
kind: ConfigMap 
metadata:
  name: tomcat-users 
data:
  tomcat-users.xml:  |
    <?xml version='1.0' encoding='utf-8'?>
    <tomcat-users xmlns="http://tomcat.apache.org/xml"
              xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
              xsi:schemaLocation="http://tomcat.apache.org/xml tomcat-users.xsd"
              version="1.0">
    <user username="tomcat" password="tomcat" roles="admin-gui,manager-gui"/>
    </tomcat-users>

---
apiVersion: v1
kind: ReplicationController
metadata:
  name: webapp-rc
  namespace: dev
spec:
  selector:
    app: webapp
  template:
    metadata:
      name: webapp-pod
      labels:
        app: webapp
    spec:
      volumes:
      - name: tomcat-userconf
      configMap:
        items:
        - key: "tomcat-users.xml"
          path: "tomcat-users.xml"
      containers:
      - name: webapp-c
        image: acadalearning/java-web-app
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: tomcat-userconf
        mountPath: /usr/local/tomcat/conf/tomcat-users.xml
        subPath: "tomcat-users.xml"

---
apiVersion: v1
kind: Service
metadata:
  name: myapp-svc
spec:
  selector:
    app: webapp
  ports:
  - targetPort: 8080



apiVersion: v1
kind: Pod
metadata:
 name: tomcat-test-pod
spec:
 containers:
 - name: test-container
   image: tomcat:7.0
   command: [ "catalina.sh", "run" ]
   volumeMounts:
   - name: config-volume
     mountPath: /usr/local/tomcat/conf/server.xml
 volumes:
 - name: config-volume
   configMap:
    name: tomcat-users 
    # Provide the name of the ConfigMap containing the files you want
    # to add to the container
- name: config-volume
   configMap:
    # Provide the name of the ConfigMap containing the files you want
    name: tomcat-users
------------------------------------

apiVersion: v1
kind: ConfigMap
metadata:
  name: mongo-config
data:
  db-username: devdb
  acada: grafana

---
#secrets:

kind: Secret
apiVersion: v1
metadata:
  name: mongo-passwd
type: Opaque
stringData: 
  db-password: ZGV2ZGJAMTIz = 10001010111010101010101

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: springapp
  namespace: dev
spec:
  selector:
    matchLabels:
      app: springapp
  replicas: 3
  template:
    metadata:
      name: springapp
      labels:
        app: springapp
    spec:
      containers:
      - name: springapp
        image: acadalearning/spring-boot-mongo
        ports:
        - containerPort: 8080
        env:
        - name: MONGO_DB_USERNAME
          valueFrom:
            configMapKeyRef:
              name: mongo-config
              key: db-username
        - name: MONGO_DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mongo-passwd
              key: db-password
        - name: MONGO_DB_HOSTNAME
          value: mongo

---
apiVersion: v1
kind: Service
metadata:
  name: springapp
spec:
  selector:
    app: springapp
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer


-----------------------------------
Health Check:

*Readiness probes
*liveness probes
*startup probes

*readiness probe clears the system after detecting the errors by the *liveness probe, so that
traffic will be routed seamlessly.
*startup increases the expected time for delayed or slow start up container.



my node is 200G = host

15bm
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myapp-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      tier: myapp
  template:
    metadata:
      name: myapp-pod
      labels:
        tier: myapp
    spec:
      containers:
      - name: myapp-c
        image: acadalearning/myapp
        ports:
        - containerPort: 8080
        livenessProbe:
          httpGet:
            path: /web-app
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /web-app
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        startupProbe:
          httpGet:
            path: /web-app
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
      hard:
        cpu: "30"
        memory: 50Gi
        pods: 5
---
apiVersion: v1
kind: Service
metadata:
  name: myapp-svc
spec:
  selector:
    tier: myapp
  ports:
  - targetPort: 8080
    port: 80
    nodePort: 30200
  type: NodePort



http://3.80.55.201:30200/web-app/


http://3.80.55.201:30200/web-app/


pod/myapp-rs-wzj9c 

HCL
.tf

terraform init

terraform validate

terraform plan

terraform apply 

terraform destroy 



#!/bin/bash
curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/aws-iam-authenticator
curl -o aws-iam-authenticator.sha256 https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/aws-iam-authenticator.sha256
openssl sha1 -sha256 aws-iam-authenticator
chmod +x ./aws-iam-authenticator
mkdir -p $HOME/bin && cp ./aws-iam-authenticator $HOME/bin/aws-iam-authenticator && export PATH=$PATH:$HOME/bin
echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
