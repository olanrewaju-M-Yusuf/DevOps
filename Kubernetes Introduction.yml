ACADA Learning:  Kubernetes   || k8s 

Kubernetes is an ochestration engine and open-source platform
we use it to manage containarized applciations

1. Container ochestration
2. Container management 

Benefits:
  container deployement
  automated scaling 
  container management and ochestration
  load balancing
  Open source
  horizontal scaling
  optimizing cost 
  self healing 
  cloud migration

  kubernetes was released on july 21, 2015

  1-5 years 

  kubernetes achitecure:
    Service Discovery

Control plane/master:
  API server
  etcd
  scheduler
  Controller manager

Worker Nodes:
  kubelet
  kube-proxy

Command Line utility:
  for Docker    [ docker ] docker build
  for maven      [ mvn ]      mvn package
  for k8s       [ kubectl ]   kubectl apply 


  Kubernetes components 

  Cluster  -----> Worker Nodes  --->  pods  ----> Containers  ---> images ---> Appplication and Base image

Kubernetes Objects:
  Controller Manager:
    ReplicationController
    Deployment
    ReplicaSet
    DaemonSet
    StatefulSets
    Job

  Service:
    ClusterIP
    Service
    NodePort
    LoadBalancer
    ExternalName


  https://labs.play-with-k8s.com/

  Installtion of K8S:
    1. Self managed   --- Manage the control plane
    2. Managed / Cloud Managed  ---  Cloud provider is managing the control plane
 
    1. Self managed:
      minikube    --- single node cluster
      kubeadm     --- we can setup multiple nodes withing a cluster

    2. Managed/Cloud Managed:
      EKS        ---  Elastic Kubernetes Service (AWS)
      AKS        ---  Azure Kubernetes Service  (Azure)
      GKE        ---  Google Kubernetes Engine   (GCP)

      KOPS

  How do we deploy in docker:
    Imperative       -----  command
    docker run / create 
    docker service create


    Declarative --- Files + command
    docker-compose up
    docker-compose down
    docker stack deploy --docker-compose-file web.yml

  How do deploy in K8s:
    Imperative  --Command
    kubectl create namespace test
    kubectl create ns prod

    Declarative --File (Manifest files) + commands
    track file/record


Open all Port:

Kubernetes Installtion:
#!/bin/bash
# t2 Medium
# Common stages for both master and worker nodes
# This can be use as user data in launch template or launch configutions
sudo hostname master
sudo -i
sudo swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

sudo apt update -y
sudo apt install -y apt-transport-https -y

sudo curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

sudo cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
sudo apt update -y
sudo apt install -y kubelet kubeadm  containerd kubectl
# apt-mark hold will prevent the package from being automatically upgraded or removed.

sudo apt-mark hold kubelet kubeadm kubectl containerd

sudo cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

sudo cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF

sudo sysctl --system

sudo mkdir -p /etc/containerd
sudo containerd config default | sudo tee /etc/containerd/config.toml
sudo systemctl restart containerd

# Enable and start kubelet service
sudo systemctl daemon-reload
sudo systemctl start kubelet
sudo systemctl enable kubelet.service

#step2
kubeadm init

#step3
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config      

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

#Step4
sudo kubeadm join 172.31.24.209:6443 --token 8bdmlp.0v7ee3j8rj8gcuvs \
        --discovery-token-ca-cert-hash sha256:edb07e2a5094746fb48fb9e270878423ffb7cde60ca05c654710b5839d6d8dc6


kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml



creating namespace using Declarative file (Manifest file)

.yaml .yml

namespaces:
  Is a virtual cluster within your cluster
  Is it use to isolate your environment/ projects/teams
  used for securing k8s

namespaces = ns

how we deploy in k8s:
*Imperative 
kubectl get ns

kubectl create ns test
kubectl get ns

*Declarative
we deploy using Manifest files .yml

apiVersion: v1
kind: Namespace
metadata:
  name: prod

kubectl apply -f ns.yml --dry-run=client


apiVersion: v1
kind: Pod
metadata:
  name: webapp
  namespace: dev
  label: 
    app: webapp
spec:
  containers:
  - name: webapp
    image: acadalearning/java-web-app
    ports:
    - containerPort: 8080


kubectl config set-context --current --namespace=dev
kubectl get pod
